{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e3900a-3e98-4787-9b33-f7ecdebd2334",
   "metadata": {},
   "source": [
    "Implement on Intel® Developer Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae21d7-2418-435c-8e41-4f5296081159",
   "metadata": {
    "tags": []
   },
   "source": [
    "# I. Set Up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5f6b1-2ee9-43d7-b0aa-ac29949190ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1. Init conda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe118e-3088-4d83-a3e9-c0974c981caf",
   "metadata": {},
   "source": [
    "Run this command in console:\n",
    "\n",
    "```bash\n",
    "$ conda init\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb347a-1c38-4b74-893d-9c615bfd4902",
   "metadata": {},
   "source": [
    "NOTE: After this command, you should **restart console manually** to use conda. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9517da-644d-4394-9fea-491ce0e3004b",
   "metadata": {},
   "source": [
    "## Step 2. Create a Intel® Extension for PyTorch* environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a1bfc-6f06-47f9-95b8-82cd05115cfa",
   "metadata": {},
   "source": [
    "Create a new environment with **[Intel® Extension for PyTorch*](https://github.com/intel/intel-extension-for-pytorch)**, run the following commands in console:\n",
    "\n",
    "```bash\n",
    "# apply Intel® Extension for PyTorch* for the new environment\n",
    "$ conda create -n seg --clone pytorch\n",
    "$ conda activate seg\n",
    "$ conda install -c anaconda ipykernel\n",
    "$ python -m ipykernel install --user --name seg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ee8e7-328d-4456-b95f-d5a50e55e7ff",
   "metadata": {},
   "source": [
    "NOTE: Please **switch current jupyter kernel to `seg`** for new environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261edd8-2c14-45c3-8fbd-1f9dabec267e",
   "metadata": {},
   "source": [
    "## Step 3. Install MMSegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283089b5-811e-4ce4-bf2d-80ecc8d6be80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Run the following commands in console:\n",
    "\n",
    "```bash\n",
    "# install mim\n",
    "$ pip install -U openmim \n",
    "$ mim install mmengine\n",
    "\n",
    "# install mmcv\n",
    "$ git clone https://github.com/open-mmlab/mmcv.git\n",
    "$ cd mmcv\n",
    "$ pip install -r requirements/optional.txt\n",
    "$ pip install -e . -v\n",
    "$ cd ..\n",
    "\n",
    "# install mmseg\n",
    "$ git clone -b main https://github.com/open-mmlab/mmsegmentation.git\n",
    "$ cd mmsegmentation\n",
    "$ pip install -v -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de096e3-d85d-4b96-bf99-41ef0c09dbe5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# II. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2af41a-8dc2-4e4b-a18d-2ef2399071cf",
   "metadata": {},
   "source": [
    "Create a `data` directory and a `cityscapes` directory. Download <u>leftImg8bit_trainvaltest.zip</u> and <u>gtFine_trainvaltest.zip</u> in [Cityscapes](https://www.cityscapes-dataset.com). Unzip files as follows:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29415457-6bec-4be7-97ea-7f332e922e63",
   "metadata": {},
   "source": [
    "mmsegmentation\n",
    "├── mmseg\n",
    "├── tools\n",
    "├── configs\n",
    "├── data\n",
    "│   ├── cityscapes\n",
    "│   │   ├── leftImg8bit\n",
    "│   │   │   ├── train\n",
    "│   │   │   ├── val\n",
    "│   │   │   ├── test\n",
    "│   │   ├── gtFine\n",
    "│   │   │   ├── train\n",
    "│   │   │   ├── val\n",
    "│   │   │   ├── test (no label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c0385f-4a8d-433c-a178-e1fc53cfc370",
   "metadata": {},
   "source": [
    "Make sure current working directory is `mmsegmentation`, run the following commands in console:\n",
    "\n",
    "```bash\n",
    "# create directories\n",
    "$ mkdir data \n",
    "$ cd data && mkdir cityscapes\n",
    "```\n",
    "NOTE: Here you should **download [dataset](https://www.cityscapes-dataset.com) to the path: `data/cityscapes`**\n",
    "```bash\n",
    "# unzip data files\n",
    "$ unzip data/cityscapes/leftImg8bit_trainvaltest.zip\n",
    "$ unzip data/cityscapes/gtFine_trainvaltest.zip\n",
    "\n",
    "# install cityscapesscripts\n",
    "$ python -m pip install cityscapesscripts\n",
    "\n",
    "# convert dataset to mmsegmentation format\n",
    "$ python tools/dataset_converters/cityscapes.py data/cityscapes --nproc 8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f231b32e-de9f-40f9-a2ee-2bcd25aa963c",
   "metadata": {},
   "source": [
    "# III. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129cda53-5634-4843-ad22-d07ef389293a",
   "metadata": {},
   "source": [
    "## Step 1. Load a checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04520182-de98-40a1-9148-b59340296363",
   "metadata": {},
   "source": [
    "Since a well-performed real-time semantic segmentation model [STDC](https://ieeexplore.ieee.org/document/9577672) has already been trained by OpenMMLab, we can directly use the [checkpoint](https://download.openmmlab.com/mmsegmentation/v0.5/stdc/stdc2_512x1024_80k_cityscapes/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth). Download this checkpoint by `mim download`.\n",
    "\n",
    "```bash\n",
    "$ mim download mmsegmentation --config stdc2_4xb12-80k_cityscapes-512x1024 --dest .\n",
    "$ mkdir ckpt\n",
    "$ mv stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth ckpt/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ef587-bcbd-4305-bb30-b46bba103552",
   "metadata": {},
   "source": [
    "We can see a checkpoint and its config file:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b5ba72f-5ec2-46bf-abb7-b6f5dde98ecf",
   "metadata": {},
   "source": [
    "mmsegmentation\n",
    "├── mmseg\n",
    "├── tools\n",
    "├── configs\n",
    "│   ├── stdc\n",
    "│       ├── stdc2_4xb12-80k_cityscapes-512x1024.py # config\n",
    "├── ckpt\n",
    "│   ├── stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth  # checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedf718-ab03-4781-813e-4c8b463c00a6",
   "metadata": {},
   "source": [
    "## Step 2. Evaluate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704202dc-d98f-4671-aed1-69d1030c5d9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Performance Evaluation (mIoU & PA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f800c1a-37e0-487e-8615-932cd3f8e7a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **1.1 Evaluation on valid set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed3051b-1c7f-410c-811f-70c0c6d3f669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/23 23:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.16 (main, Jun 15 2023, 02:33:25) [GCC 13.1.0]\n",
      "    CUDA available: False\n",
      "    numpy_random_seed: 1319581051\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.0.1a0+cxx11.abi\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.2\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=OFF, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2a0+cxx11.abi\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.9.0\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1319581051\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "10/23 23:33:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "crop_size = (\n",
      "    512,\n",
      "    1024,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/cityscapes/'\n",
      "dataset_type = 'CityscapesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=8000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = 'ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=[\n",
      "        dict(\n",
      "            align_corners=False,\n",
      "            channels=64,\n",
      "            concat_input=False,\n",
      "            in_channels=128,\n",
      "            in_index=2,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=19,\n",
      "            num_convs=1,\n",
      "            sampler=dict(min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "            type='FCNHead'),\n",
      "        dict(\n",
      "            align_corners=False,\n",
      "            channels=64,\n",
      "            concat_input=False,\n",
      "            in_channels=128,\n",
      "            in_index=1,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=19,\n",
      "            num_convs=1,\n",
      "            sampler=dict(min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "            type='FCNHead'),\n",
      "        dict(\n",
      "            align_corners=True,\n",
      "            boundary_threshold=0.1,\n",
      "            channels=64,\n",
      "            concat_input=False,\n",
      "            in_channels=256,\n",
      "            in_index=0,\n",
      "            loss_decode=[\n",
      "                dict(\n",
      "                    loss_name='loss_ce',\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=True),\n",
      "                dict(loss_name='loss_dice', loss_weight=1.0, type='DiceLoss'),\n",
      "            ],\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=2,\n",
      "            num_convs=1,\n",
      "            type='STDCHead'),\n",
      "    ],\n",
      "    backbone=dict(\n",
      "        backbone_cfg=dict(\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            bottleneck_type='cat',\n",
      "            channels=(\n",
      "                32,\n",
      "                64,\n",
      "                256,\n",
      "                512,\n",
      "                1024,\n",
      "            ),\n",
      "            in_channels=3,\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_convs=4,\n",
      "            stdc_type='STDCNet2',\n",
      "            type='STDCNet',\n",
      "            with_final_conv=False),\n",
      "        ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),\n",
      "        last_in_channels=(\n",
      "            1024,\n",
      "            512,\n",
      "        ),\n",
      "        out_channels=128,\n",
      "        type='STDCContextPathNet'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            1024,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=True,\n",
      "        channels=256,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=256,\n",
      "        in_index=3,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=19,\n",
      "        num_convs=1,\n",
      "        sampler=dict(min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "        type='FCNHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(begin=0, by_epoch=False, end=1000, start_factor=0.1, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1000,\n",
      "        by_epoch=False,\n",
      "        end=80000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
      "        data_root='data/cityscapes/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='CityscapesDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=80000, type='IterBasedTrainLoop', val_interval=8000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=12,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
      "        data_root='data/cityscapes/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    1024,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='CityscapesDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
      "        data_root='data/cityscapes/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='CityscapesDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/stdc2_4xb12-80k_cityscapes-512x1024'\n",
      "\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/structures/sampler/builder.py:11: UserWarning: ``build_pixel_sampler`` would be deprecated soon, please use ``mmseg.registry.TASK_UTILS.build()`` \n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "10/23 23:33:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "/home/u204644/code/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n",
      "10/23 23:33:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "10/23 23:33:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "Loads checkpoint by local backend from path: ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth\n",
      "10/23 23:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (128, 256) is `x+1` and out size (1024, 2048) is `nx+1`\n",
      "  warnings.warn(\n",
      "10/23 23:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 50/500]    eta: 0:06:26  time: 0.8156  data_time: 0.0123  \n",
      "10/23 23:35:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/500]    eta: 0:05:44  time: 0.9798  data_time: 0.0119  \n",
      "10/23 23:35:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [150/500]    eta: 0:04:58  time: 0.8164  data_time: 0.0122  \n",
      "10/23 23:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/500]    eta: 0:04:17  time: 0.9127  data_time: 0.0127  \n",
      "10/23 23:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [250/500]    eta: 0:03:32  time: 0.8155  data_time: 0.0124  \n",
      "10/23 23:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/500]    eta: 0:02:49  time: 0.8022  data_time: 0.0122  \n",
      "10/23 23:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [350/500]    eta: 0:02:06  time: 0.8106  data_time: 0.0122  \n",
      "10/23 23:39:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/500]    eta: 0:01:23  time: 0.7893  data_time: 0.0122  \n",
      "10/23 23:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/500]    eta: 0:00:41  time: 0.8148  data_time: 0.0119  \n",
      "10/23 23:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    eta: 0:00:00  time: 0.7478  data_time: 0.0123  \n",
      "10/23 23:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "10/23 23:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|      road     | 97.95 | 98.73 |\n",
      "|    sidewalk   | 83.38 |  92.3 |\n",
      "|    building   | 91.39 | 95.95 |\n",
      "|      wall     | 49.44 | 54.97 |\n",
      "|     fence     | 55.44 | 65.32 |\n",
      "|      pole     | 56.73 | 69.19 |\n",
      "| traffic light | 63.76 | 74.31 |\n",
      "|  traffic sign | 74.26 |  81.3 |\n",
      "|   vegetation  | 91.37 | 96.45 |\n",
      "|    terrain    | 61.42 | 73.17 |\n",
      "|      sky      | 93.96 |  97.5 |\n",
      "|     person    | 77.92 | 89.19 |\n",
      "|     rider     |  56.9 | 69.93 |\n",
      "|      car      | 94.03 | 97.59 |\n",
      "|     truck     | 69.95 | 75.66 |\n",
      "|      bus      | 81.08 | 89.89 |\n",
      "|     train     | 64.09 | 71.42 |\n",
      "|   motorcycle  | 53.39 | 62.44 |\n",
      "|    bicycle    | 73.28 | 87.19 |\n",
      "+---------------+-------+-------+\n",
      "10/23 23:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    aAcc: 95.4200  mIoU: 73.1500  mAcc: 81.1800  data_time: 0.0129  time: 0.8349\n"
     ]
    }
   ],
   "source": [
    "!~/.conda/envs/seg/bin/python tools/test.py configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad24cf24-29e7-4902-b39d-63acfb27843e",
   "metadata": {},
   "source": [
    "##### **Test time augmentation (TTA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794daea-3719-404c-8da7-fe7bbdf64ebf",
   "metadata": {},
   "source": [
    "Add the following code in `configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py` for valid set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ded301-2596-4cb7-9547-e6070e0a7f7d",
   "metadata": {},
   "source": [
    "```python\n",
    "tta_model = dict(type='SegTTAModel')\n",
    "tta_pipeline = [\n",
    "    dict(backend_args=None, type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        transforms=[\n",
    "            [\n",
    "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
    "            ],\n",
    "            [\n",
    "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
    "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
    "            ],\n",
    "            [\n",
    "                dict(type='LoadAnnotations'),\n",
    "            ],\n",
    "            [\n",
    "                dict(type='PackSegInputs'),\n",
    "            ],\n",
    "        ],\n",
    "        type='TestTimeAug'),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421d3e6-fcb8-4ce4-a070-e500f0824bf9",
   "metadata": {},
   "source": [
    "Inference with TTA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81739d6e-8fe5-45a8-ae9c-20dbc07c83df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/23 23:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.16 (main, Jun 15 2023, 02:33:25) [GCC 13.1.0]\n",
      "    CUDA available: False\n",
      "    numpy_random_seed: 1209058460\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.0.1a0+cxx11.abi\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.2\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=OFF, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2a0+cxx11.abi\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.9.0\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 1209058460\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "10/23 23:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "crop_size = (\n",
      "    512,\n",
      "    1024,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/cityscapes/'\n",
      "dataset_type = 'CityscapesDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=8000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = 'ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    module=dict(\n",
      "        auxiliary_head=[\n",
      "            dict(\n",
      "                align_corners=False,\n",
      "                channels=64,\n",
      "                concat_input=False,\n",
      "                in_channels=128,\n",
      "                in_index=2,\n",
      "                loss_decode=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_classes=19,\n",
      "                num_convs=1,\n",
      "                sampler=dict(\n",
      "                    min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "                type='FCNHead'),\n",
      "            dict(\n",
      "                align_corners=False,\n",
      "                channels=64,\n",
      "                concat_input=False,\n",
      "                in_channels=128,\n",
      "                in_index=1,\n",
      "                loss_decode=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_classes=19,\n",
      "                num_convs=1,\n",
      "                sampler=dict(\n",
      "                    min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "                type='FCNHead'),\n",
      "            dict(\n",
      "                align_corners=True,\n",
      "                boundary_threshold=0.1,\n",
      "                channels=64,\n",
      "                concat_input=False,\n",
      "                in_channels=256,\n",
      "                in_index=0,\n",
      "                loss_decode=[\n",
      "                    dict(\n",
      "                        loss_name='loss_ce',\n",
      "                        loss_weight=1.0,\n",
      "                        type='CrossEntropyLoss',\n",
      "                        use_sigmoid=True),\n",
      "                    dict(\n",
      "                        loss_name='loss_dice',\n",
      "                        loss_weight=1.0,\n",
      "                        type='DiceLoss'),\n",
      "                ],\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_classes=2,\n",
      "                num_convs=1,\n",
      "                type='STDCHead'),\n",
      "        ],\n",
      "        backbone=dict(\n",
      "            backbone_cfg=dict(\n",
      "                act_cfg=dict(type='ReLU'),\n",
      "                bottleneck_type='cat',\n",
      "                channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    256,\n",
      "                    512,\n",
      "                    1024,\n",
      "                ),\n",
      "                in_channels=3,\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_convs=4,\n",
      "                stdc_type='STDCNet2',\n",
      "                type='STDCNet',\n",
      "                with_final_conv=False),\n",
      "            ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),\n",
      "            last_in_channels=(\n",
      "                1024,\n",
      "                512,\n",
      "            ),\n",
      "            out_channels=128,\n",
      "            type='STDCContextPathNet'),\n",
      "        data_preprocessor=dict(\n",
      "            bgr_to_rgb=True,\n",
      "            mean=[\n",
      "                123.675,\n",
      "                116.28,\n",
      "                103.53,\n",
      "            ],\n",
      "            pad_val=0,\n",
      "            seg_pad_val=255,\n",
      "            size=(\n",
      "                512,\n",
      "                1024,\n",
      "            ),\n",
      "            std=[\n",
      "                58.395,\n",
      "                57.12,\n",
      "                57.375,\n",
      "            ],\n",
      "            type='SegDataPreProcessor'),\n",
      "        decode_head=dict(\n",
      "            align_corners=True,\n",
      "            channels=256,\n",
      "            concat_input=False,\n",
      "            dropout_ratio=0.1,\n",
      "            in_channels=256,\n",
      "            in_index=3,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=19,\n",
      "            num_convs=1,\n",
      "            sampler=dict(min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "            type='FCNHead'),\n",
      "        pretrained=None,\n",
      "        test_cfg=dict(mode='whole'),\n",
      "        train_cfg=dict(),\n",
      "        type='EncoderDecoder'),\n",
      "    type='SegTTAModel')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(begin=0, by_epoch=False, end=1000, start_factor=0.1, type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1000,\n",
      "        by_epoch=False,\n",
      "        end=80000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
      "        data_root='data/cityscapes/',\n",
      "        pipeline=[\n",
      "            dict(backend_args=None, type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                transforms=[\n",
      "                    [\n",
      "                        dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                        dict(\n",
      "                            keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                        dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                        dict(\n",
      "                            keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                        dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                        dict(\n",
      "                            keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "                    ],\n",
      "                    [\n",
      "                        dict(\n",
      "                            direction='horizontal',\n",
      "                            prob=0.0,\n",
      "                            type='RandomFlip'),\n",
      "                        dict(\n",
      "                            direction='horizontal',\n",
      "                            prob=1.0,\n",
      "                            type='RandomFlip'),\n",
      "                    ],\n",
      "                    [\n",
      "                        dict(type='LoadAnnotations'),\n",
      "                    ],\n",
      "                    [\n",
      "                        dict(type='PackSegInputs'),\n",
      "                    ],\n",
      "                ],\n",
      "                type='TestTimeAug'),\n",
      "        ],\n",
      "        type='CityscapesDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=80000, type='IterBasedTrainLoop', val_interval=8000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=12,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),\n",
      "        data_root='data/cityscapes/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    1024,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='CityscapesDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(\n",
      "    module=dict(\n",
      "        auxiliary_head=[\n",
      "            dict(\n",
      "                align_corners=False,\n",
      "                channels=64,\n",
      "                concat_input=False,\n",
      "                in_channels=128,\n",
      "                in_index=2,\n",
      "                loss_decode=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_classes=19,\n",
      "                num_convs=1,\n",
      "                sampler=dict(\n",
      "                    min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "                type='FCNHead'),\n",
      "            dict(\n",
      "                align_corners=False,\n",
      "                channels=64,\n",
      "                concat_input=False,\n",
      "                in_channels=128,\n",
      "                in_index=1,\n",
      "                loss_decode=dict(\n",
      "                    loss_weight=1.0,\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False),\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_classes=19,\n",
      "                num_convs=1,\n",
      "                sampler=dict(\n",
      "                    min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "                type='FCNHead'),\n",
      "            dict(\n",
      "                align_corners=True,\n",
      "                boundary_threshold=0.1,\n",
      "                channels=64,\n",
      "                concat_input=False,\n",
      "                in_channels=256,\n",
      "                in_index=0,\n",
      "                loss_decode=[\n",
      "                    dict(\n",
      "                        loss_name='loss_ce',\n",
      "                        loss_weight=1.0,\n",
      "                        type='CrossEntropyLoss',\n",
      "                        use_sigmoid=True),\n",
      "                    dict(\n",
      "                        loss_name='loss_dice',\n",
      "                        loss_weight=1.0,\n",
      "                        type='DiceLoss'),\n",
      "                ],\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_classes=2,\n",
      "                num_convs=1,\n",
      "                type='STDCHead'),\n",
      "        ],\n",
      "        backbone=dict(\n",
      "            backbone_cfg=dict(\n",
      "                act_cfg=dict(type='ReLU'),\n",
      "                bottleneck_type='cat',\n",
      "                channels=(\n",
      "                    32,\n",
      "                    64,\n",
      "                    256,\n",
      "                    512,\n",
      "                    1024,\n",
      "                ),\n",
      "                in_channels=3,\n",
      "                norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "                num_convs=4,\n",
      "                stdc_type='STDCNet2',\n",
      "                type='STDCNet',\n",
      "                with_final_conv=False),\n",
      "            ffm_cfg=dict(in_channels=384, out_channels=256, scale_factor=4),\n",
      "            last_in_channels=(\n",
      "                1024,\n",
      "                512,\n",
      "            ),\n",
      "            out_channels=128,\n",
      "            type='STDCContextPathNet'),\n",
      "        data_preprocessor=dict(\n",
      "            bgr_to_rgb=True,\n",
      "            mean=[\n",
      "                123.675,\n",
      "                116.28,\n",
      "                103.53,\n",
      "            ],\n",
      "            pad_val=0,\n",
      "            seg_pad_val=255,\n",
      "            size=(\n",
      "                512,\n",
      "                1024,\n",
      "            ),\n",
      "            std=[\n",
      "                58.395,\n",
      "                57.12,\n",
      "                57.375,\n",
      "            ],\n",
      "            type='SegDataPreProcessor'),\n",
      "        decode_head=dict(\n",
      "            align_corners=True,\n",
      "            channels=256,\n",
      "            concat_input=False,\n",
      "            dropout_ratio=0.1,\n",
      "            in_channels=256,\n",
      "            in_index=3,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=19,\n",
      "            num_convs=1,\n",
      "            sampler=dict(min_kept=10000, thresh=0.7, type='OHEMPixelSampler'),\n",
      "            type='FCNHead'),\n",
      "        pretrained=None,\n",
      "        test_cfg=dict(mode='whole'),\n",
      "        train_cfg=dict(),\n",
      "        type='EncoderDecoder'),\n",
      "    type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),\n",
      "        data_root='data/cityscapes/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='CityscapesDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/stdc2_4xb12-80k_cityscapes-512x1024'\n",
      "\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/structures/sampler/builder.py:11: UserWarning: ``build_pixel_sampler`` would be deprecated soon, please use ``mmseg.registry.TASK_UTILS.build()`` \n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/decode_heads/decode_head.py:120: UserWarning: For binary segmentation, we suggest using`out_channels = 1` to define the outputchannels of segmentor, and use `threshold`to convert `seg_logits` into a predictionapplying a threshold\n",
      "  warnings.warn('For binary segmentation, we suggest using'\n",
      "10/23 23:51:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "/home/u204644/code/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n",
      "10/23 23:51:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "10/23 23:51:18 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "Loads checkpoint by local backend from path: ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth\n",
      "10/23 23:51:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (64, 128) is `x+1` and out size (512, 1024) is `nx+1`\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (96, 192) is `x+1` and out size (768, 1536) is `nx+1`\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (128, 256) is `x+1` and out size (1024, 2048) is `nx+1`\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (160, 320) is `x+1` and out size (1280, 2560) is `nx+1`\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (192, 384) is `x+1` and out size (1536, 3072) is `nx+1`\n",
      "  warnings.warn(\n",
      "/home/u204644/code/mmsegmentation/mmseg/models/utils/wrappers.py:22: UserWarning: When align_corners=True, the output would more aligned if input size (224, 448) is `x+1` and out size (1792, 3584) is `nx+1`\n",
      "  warnings.warn(\n",
      "/home/u204644/.local/lib/python3.9/site-packages/mmengine/structures/pixel_data.py:83: UserWarning: The shape of value will convert from torch.Size([1024, 2048]) to torch.Size([1, 1024, 2048])\n",
      "  warnings.warn('The shape of value will convert from '\n",
      "10/24 00:02:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 50/500]    eta: 1:40:00  time: 12.8965  data_time: 0.0634  \n",
      "10/24 00:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/500]    eta: 1:27:29  time: 12.9164  data_time: 0.0557  \n",
      "10/24 00:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [150/500]    eta: 1:16:10  time: 12.9285  data_time: 0.0529  \n",
      "10/24 00:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/500]    eta: 1:05:09  time: 12.9387  data_time: 0.0533  \n",
      "10/24 00:45:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [250/500]    eta: 0:54:16  time: 13.0230  data_time: 0.0519  \n",
      "10/24 00:56:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/500]    eta: 0:43:27  time: 13.1429  data_time: 0.0523  \n",
      "10/24 01:07:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [350/500]    eta: 0:32:40  time: 13.3772  data_time: 0.0516  \n",
      "10/24 01:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/500]    eta: 0:21:57  time: 13.8954  data_time: 0.0517  \n",
      "10/24 01:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/500]    eta: 0:11:03  time: 14.1540  data_time: 0.0623  \n",
      "10/24 01:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    eta: 0:00:00  time: 13.8732  data_time: 0.0672  \n",
      "10/24 01:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "10/24 01:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|      road     | 98.17 |  98.9 |\n",
      "|    sidewalk   | 84.71 | 92.89 |\n",
      "|    building   | 92.08 | 96.41 |\n",
      "|      wall     |  55.3 | 59.73 |\n",
      "|     fence     | 58.28 | 66.37 |\n",
      "|      pole     | 60.26 |  71.0 |\n",
      "| traffic light | 66.61 | 75.16 |\n",
      "|  traffic sign | 76.56 | 81.88 |\n",
      "|   vegetation  | 91.95 | 96.85 |\n",
      "|    terrain    | 63.66 | 73.97 |\n",
      "|      sky      |  94.4 | 97.63 |\n",
      "|     person    | 80.11 | 90.75 |\n",
      "|     rider     | 59.68 | 71.48 |\n",
      "|      car      |  94.5 | 97.98 |\n",
      "|     truck     | 71.71 | 75.56 |\n",
      "|      bus      |  86.2 | 91.09 |\n",
      "|     train     | 76.87 | 81.91 |\n",
      "|   motorcycle  |  60.1 | 66.95 |\n",
      "|    bicycle    | 75.37 | 88.73 |\n",
      "+---------------+-------+-------+\n",
      "10/24 01:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [500/500]    aAcc: 95.8500  mIoU: 76.1300  mAcc: 82.9100  data_time: 0.0571  time: 13.3530\n"
     ]
    }
   ],
   "source": [
    "!~/.conda/envs/seg/bin/python tools/test.py configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth --tta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f3dd5c-57b8-4f78-93a6-706c0c494d17",
   "metadata": {},
   "source": [
    "#### **1.2 Evaluation on test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27774ec-b4e6-4b7f-b7ab-f6f965f27930",
   "metadata": {},
   "source": [
    "NOTE: Since metric results are given by [Cityscapes](https://www.cityscapes-dataset.com), we only share methods in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947c698-fb49-49d5-abc7-e7e2732ff94a",
   "metadata": {},
   "source": [
    "Add the following configuration in `configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075493d9-9c91-48dd-a462-9e2a9789fe4b",
   "metadata": {},
   "source": [
    "```python\n",
    "test_evaluator = dict(\n",
    "    type='CityscapesMetric',\n",
    "    format_only=True,\n",
    "    keep_results=True,\n",
    "    output_dir='work_dirs/format_results') # result dir\n",
    "test_dataloader = dict(\n",
    "    batch_size=1,\n",
    "    num_workers=4,\n",
    "    persistent_workers=True,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type='CityscapesDataset',\n",
    "        data_root='data/cityscapes/',\n",
    "        data_prefix=dict(img_path='leftImg8bit/test'),\n",
    "        pipeline=[\n",
    "            dict(type='LoadImageFromFile'),\n",
    "            dict(type='Resize', scale=(2048, 1024), keep_ratio=True),\n",
    "            dict(type='PackSegInputs')\n",
    "        ]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba04489-4c19-42da-8f52-1e474d9a2bc7",
   "metadata": {},
   "source": [
    "Run the following command and submit segmetation results (in `work_dirs/format_results`) to [Cityscapes](https://www.cityscapes-dataset.com):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179882b1-c6db-4f23-b1eb-302bc4973439",
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.conda/envs/seg/bin/python tools/test.py configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dfaac7-0222-4d44-bf58-ef697e052c8e",
   "metadata": {},
   "source": [
    "##### **Test time augmentation (TTA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c34c65-89f9-41a8-b234-41deb46fa217",
   "metadata": {},
   "source": [
    "Add the following code in `configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py` for test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fafd93-13e6-4fbf-8665-23444c923807",
   "metadata": {},
   "source": [
    "```python\n",
    "tta_model = dict(type='SegTTAModel')\n",
    "tta_pipeline = [\n",
    "    dict(backend_args=None, type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        transforms=[\n",
    "            [\n",
    "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
    "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
    "            ],\n",
    "            [\n",
    "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
    "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
    "            ],\n",
    "#             [\n",
    "#                 dict(type='LoadAnnotations'),\n",
    "#             ],\n",
    "            [\n",
    "                dict(type='PackSegInputs'),\n",
    "            ],\n",
    "        ],\n",
    "        type='TestTimeAug'),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115bb4e-9aef-4316-aee8-77d553d2ed3f",
   "metadata": {},
   "source": [
    "Inference with TTA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223080c1-fcb6-4f6a-9d21-f3ad2deafe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!~/.conda/envs/seg/bin/python tools/test.py configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py ckpt/stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth --tta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6652b7f-1037-46f6-b942-7b0e989e1bf2",
   "metadata": {},
   "source": [
    "### 2. Quantization & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4816649-ba6d-40bd-b79b-93212892100c",
   "metadata": {},
   "source": [
    "#### 2.1 Prepare the deploy evironment.\n",
    "\n",
    "Run the following quantization and deployment code based on Intel Openvino.\n",
    "\n",
    "```bash\n",
    "$ https://github.com/open-mmlab/mmdeploy.git\n",
    "$ pip install openvino-dev\n",
    "$ cd mmdeploy\n",
    "```\n",
    "\n",
    "Quantize and deploy the desired model:\n",
    "\n",
    "```bash\n",
    "$ ~/.conda/envs/seg/bin/python tools/deploy.py \\\n",
    "            configs/mmseg/segmentation_openvino_static-1024x2048.py \\\n",
    "            stdc2_4xb12-80k_cityscapes-512x1024.py  \\\n",
    "            stdc2_512x1024_80k_cityscapes_20220222_132015-fb1e3a1a.pth \\\n",
    "            demo/resources/cityscapes.png  --work-dir qaunt_models  \\\n",
    "            --device cpu --quant\n",
    "```\n",
    "\n",
    "The quantized model would be saved at `qaunt_models`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b471bb6-439a-4825-9bd3-918504ec8873",
   "metadata": {},
   "source": [
    "#### 2.2 Test the evalution time after quantization and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441682e6-7eee-4af0-810e-a76bd6fcf31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/24 02:25:59 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmseg\" in the \"Codebases\" registry tree. As a workaround, the current \"Codebases\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmseg\" is a correct scope, or whether the registry is initialized.\n",
      "10/24 02:25:59 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmseg\" in the \"mmseg_tasks\" registry tree. As a workaround, the current \"mmseg_tasks\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmseg\" is a correct scope, or whether the registry is initialized.\n",
      "10/24 02:25:59 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Failed to search registry with scope \"mmseg\" in the \"backend_segmentors\" registry tree. As a workaround, the current \"backend_segmentors\" registry in \"mmdeploy\" is used to build instance. This may cause unexpected failure when running the built modules. Please check whether \"mmseg\" is a correct scope, or whether the registry is initialized.\n",
      "10/24 02:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.9.16 (main, Jun 15 2023, 02:33:25) [GCC 13.1.0]\n",
      "    CUDA available: False\n",
      "    numpy_random_seed: 93463641\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 2.0.1a0+cxx11.abi\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.2\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.2-Product Build 20230613 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=/opt/rh/gcc-toolset-11/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=OFF, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.15.2a0+cxx11.abi\n",
      "    OpenCV: 4.8.1\n",
      "    MMEngine: 0.9.0\n",
      "\n",
      "Runtime environment:\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 93463641\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "/home/u204644/code/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n",
      "10/24 02:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "10/24 02:26:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "10/24 02:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [ 50/500]    eta: 0:02:45  time: 0.3648  data_time: 0.0060  \n",
      "10/24 02:26:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/500]    eta: 0:02:24  time: 0.3575  data_time: 0.0057  \n",
      "10/24 02:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - [openvino]-110 times per count: 291.83 ms, 3.43 FPS\n",
      "10/24 02:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [150/500]    eta: 0:02:05  time: 0.3562  data_time: 0.0062  \n",
      "10/24 02:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/500]    eta: 0:01:48  time: 0.3597  data_time: 0.0058  \n",
      "10/24 02:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - [openvino]-210 times per count: 293.14 ms, 3.41 FPS\n",
      "10/24 02:27:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [250/500]    eta: 0:01:30  time: 0.3546  data_time: 0.0057  \n",
      "10/24 02:27:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [300/500]    eta: 0:01:11  time: 0.3486  data_time: 0.0063  \n",
      "10/24 02:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - [openvino]-310 times per count: 291.99 ms, 3.42 FPS\n",
      "10/24 02:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [350/500]    eta: 0:00:53  time: 0.3524  data_time: 0.0059  \n",
      "10/24 02:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [400/500]    eta: 0:00:35  time: 0.3532  data_time: 0.0059  \n",
      "10/24 02:28:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - [openvino]-410 times per count: 292.00 ms, 3.42 FPS\n",
      "10/24 02:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [450/500]    eta: 0:00:17  time: 0.3521  data_time: 0.0062  \n",
      "10/24 02:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [500/500]    eta: 0:00:00  time: 0.3042  data_time: 0.0058  \n",
      "10/24 02:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "10/24 02:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+---------------+-------+-------+\n",
      "|     Class     |  IoU  |  Acc  |\n",
      "+---------------+-------+-------+\n",
      "|      road     | 97.95 | 98.73 |\n",
      "|    sidewalk   | 83.38 |  92.3 |\n",
      "|    building   | 91.39 | 95.95 |\n",
      "|      wall     | 49.44 | 54.97 |\n",
      "|     fence     | 55.44 | 65.32 |\n",
      "|      pole     | 56.73 | 69.19 |\n",
      "| traffic light | 63.76 | 74.31 |\n",
      "|  traffic sign | 74.27 |  81.3 |\n",
      "|   vegetation  | 91.37 | 96.45 |\n",
      "|    terrain    | 61.42 | 73.17 |\n",
      "|      sky      | 93.96 |  97.5 |\n",
      "|     person    | 77.92 | 89.19 |\n",
      "|     rider     |  56.9 | 69.93 |\n",
      "|      car      | 94.03 | 97.59 |\n",
      "|     truck     | 69.95 | 75.66 |\n",
      "|      bus      | 81.08 | 89.89 |\n",
      "|     train     | 64.09 | 71.42 |\n",
      "|   motorcycle  | 53.39 | 62.44 |\n",
      "|    bicycle    | 73.28 | 87.19 |\n",
      "+---------------+-------+-------+\n",
      "10/24 02:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [500/500]    aAcc: 95.4200  mIoU: 73.1500  mAcc: 81.1800  data_time: 0.0065  time: 0.3572\n"
     ]
    }
   ],
   "source": [
    "!cd ../mmdeploy && ~/.conda/envs/seg/bin/python tools/test.py \\\n",
    "    configs/mmseg/segmentation_openvino_static-1024x2048.py  \\\n",
    "    ../mmsegmentation/configs/stdc/stdc2_4xb12-80k_cityscapes-512x1024.py  \\\n",
    "    --model qaunt_models/end2end.onnx \\\n",
    "    --speed-test "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mm",
   "language": "python",
   "name": "mm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
